# basic liibraries
import os
import glob
import time

# data libraries
import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.inspection import permutation_importance
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
from sklearn.decomposition import PCA, SparsePCA


# model libraries
from lightgbm import LGBMClassifier
from xgboost import XGBClassifier

# terminal libraries, logger
from rich.logging import RichHandler
from rich.progress import track
import logging
from rich import print
from rich.console import Console

FORMAT = "%(message)s"
logging.basicConfig(
    level="NOTSET", format=FORMAT, datefmt="[%X]", handlers=[RichHandler()]
)

log = logging.getLogger("rich")
log.info("Starting the program ...")

# set log level
log.setLevel(logging.INFO)







# -----------------------------------------
# 1. FUNCTIONS FOR TRAINING AND EVALUATION

# dataset import function
def load_single_csv(path):
    df = pd.read_csv(path)
    log.info(f"Loaded {path}.")
    return df

# multiple dataset import function
def load_all_csv(path):
    df = pd.concat(
        [pd.read_csv(f) for f in glob.glob(path + "/*.csv")], ignore_index=True
    )
    log.info(f"Loaded all csv files from {path}.")
    return df

# split dataset into X and y
def split_dataset(df, target):
    X = df.drop(target, axis=1)
    y = df[target]
    log.info(f"Split dataset into X and y.")
    return X, y

# split dataset into train and test, 20% test size
def split_train_test(X, y):
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=0.2
    )
    log.info(f"Split dataset into train and test.")
    return X_train, X_test, y_train, y_test

# train XGBoost model
def train_xgb(X_train, y_train, X_test, y_test):
    model = XGBClassifier()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    log.info(f"Trained XGBoost model.")
    return y_pred, model

# train LightGBM model
def train_lgb(X_train, y_train, X_test, y_test):
    model = LGBMClassifier()
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    log.info(f"Trained LightGBM model.")
    return y_pred, model

# k fold cross validation for XGBoost sving the best model
def k_fold_xgboost(X, y, k=5):
    start = time.time()
    best_model = None
    best_score = 0
    best_pred = None
    for i in track(range(k), description=f"Cross validation iterating for XGBoost"):
        X_train, X_test, y_train, y_test = split_train_test(X, y)
        start_iter = time.time()
        y_pred, model = train_xgb(X_train, y_train, X_test, y_test)
        score = accuracy_score(y_test, y_pred)
        end_iter = time.time()
        log.info(f"Cross validation {i} iteration took {end_iter - start_iter} seconds.")
        if score > best_score:
            best_score = score
            best_model = model
            best_pred = y_pred
            best_y_test = y_test
            best_X_test = X_test
    end = time.time()
    log.info(f"Cross validation {i} took {end - start} seconds.")
    log.info(f"Best score: {best_score}")
    return best_model, best_pred, best_y_test, best_X_test

# k fold cross validation for LightGBM using the best model
def k_fold_lightgbm(X, y, k=5):
    start = time.time()
    best_model = None
    best_score = 0
    best_pred = None    

    for i in track(range(k), description=f"Cross validation iterating for LightGBM"):
        X_train, X_test, y_train, y_test = split_train_test(X, y)
        start_iter = time.time()
        y_pred, model = train_lgb(X_train, y_train, X_test, y_test)
        score = accuracy_score(y_test, y_pred)
        end_iter = time.time()
        log.info(f"Cross validation {i} iteration took {end_iter - start_iter} seconds.")
        if score > best_score:
            best_score = score
            best_model = model
            best_pred = y_pred
            best_y_test = y_test
            best_X_test = X_test
    end = time.time()
    log.info(f"Cross validation {i} took {end - start} seconds.")
    log.info(f"Best score: {best_score}")
    return best_model, best_pred, best_y_test, best_X_test


# PCA function
def pca(X, n_components=2):
    start = time.time()

    pca = PCA(n_components=n_components)
    X_pca = pca.fit_transform(X)
    end = time.time()
    log.info(f"PCA took {end - start} seconds.")
    return X_pca

# SPCA function
def spca(X, n_components=2):
    start = time.time()

    spca = SparsePCA(n_components=n_components)
    X_spca = spca.fit_transform(X)
    end = time.time()
    log.info(f"SPCA took {end - start} seconds.")
    return X_spca


# -----------------------------------------
# 2. FUNCTIONS FOR FEATURE IMPORTANCE

# permutation importance
# permutation importance is a model inspection technique that can be used 
# for any fitted estimator when the data is tabular. 
# This is especially useful for non-linear or opaque estimators, and works by
# shuffling each feature and measuring the loss in accuracy.
def permutation_check(model, X_test, y_test):
    start = time.time()
    perm = permutation_importance(
        model, X_test, y_test, n_repeats=10, random_state=42
    )
    end = time.time()
    log.info(f"Permutation importance took {end - start} seconds.")
    return perm

# feature importance
# feature importance is calculated by measuring the increase in the model’s
# prediction error after permuting the feature’s values, which breaks the
# relationship between the feature and the true outcome.
def feature_check(model):
    start = time.time()
    importance = model.feature_importances_
    end = time.time()
    log.info(f"Feature importance took {end - start} seconds.")
    return importance






# -----------------------------------------
# 3. FUNCTIONS FOR VISUALIZATION

# plot permutation importance
def plot_permutation_importance(X_test, perm):
    start = time.time()
    sorted_idx = perm.importances_mean.argsort()
    fig, ax = plt.figure(figsize=(10, 100)), plt.axes()
    ax.boxplot(
        perm.importances[sorted_idx].T,
        vert=False,
        labels=X_test.columns[sorted_idx],
    )
    ax.set_title("Permutation Importances (test set)")
    ax.autoscale(enable=True, axis='x', tight=True)  # Auto-range x-axis
    fig.tight_layout()
    end = time.time()
    log.info(f"Plot permutation importance took {end - start} seconds.")
    return fig, ax

# plot feature importance
def plot_feature_importance(X_test, importance):
    start = time.time()
    fig, ax = plt.figure(figsize=(10, 100)), plt.axes()
    ax.barh(X_test.columns, importance)
    ax.set_title("Feature Importances (test set)")
    fig.tight_layout()
    end = time.time()
    log.info(f"Plot feature importance took {end - start} seconds.")
    return fig, ax

# plot confusion matrix
def plot_confusion_matrix(y_test, y_pred):
    start = time.time()
    fig, ax = plt.subplots()
    cm = confusion_matrix(y_test, y_pred)
    disp = ConfusionMatrixDisplay(confusion_matrix=cm)
    disp.plot(ax=ax)
    ax.set_title("Confusion Matrix")
    fig.tight_layout()
    end = time.time()
    log.info(f"Plot confusion matrix took {end - start} seconds.")
    return fig, ax

# plot actual vs predicted
def plot_actual_vs_predicted(y_test, y_pred):
    start = time.time()
    fig, ax = plt.subplots()
    ax.scatter(y_test, y_pred)
    ax.set_xlabel("Actual")
    ax.set_ylabel("Predicted")
    ax.set_title("Actual vs Predicted")
    fig.tight_layout()
    end = time.time()
    log.info(f"Plot actual vs predicted took {end - start} seconds.")
    return fig, ax

# plot pca
def plot_pca(X_pca, y):
    start = time.time()
    fig, ax = plt.subplots()
    ax.scatter(X_pca[:, 0], X_pca[:, 1], c=y)
    ax.set_xlabel("Component 1")
    ax.set_ylabel("Component 2")
    ax.set_title("PCA")
    fig.tight_layout()
    end = time.time()
    log.info(f"Plot PCA took {end - start} seconds.")
    return fig, ax

# plot spca
def plot_spca(X_spca, y):
    start = time.time()
    fig, ax = plt.subplots()
    ax.scatter(X_spca[:, 0], X_spca[:, 1], c=y)
    ax.set_xlabel("Component 1")
    ax.set_ylabel("Component 2")
    ax.set_title("SPCA")
    fig.tight_layout()
    end = time.time()
    log.info(f"Plot SPCA took {end - start} seconds.")
    return fig, ax




# -----------------------------------------
# 4. MAIN OPTION FUNCTIONS

def xgboost_main(path, choice, df = None):

    # load dataset
    if choice == 1:
        df = load_single_csv(path)
    elif choice == 2:
        df = load_all_csv(path)
    # drop timestamp column
    df = df.drop("ts", axis=1)
    # split dataset into X and y
    X, y = split_dataset(df, target="grasp")
    log.info(f"Dataset loaded and split into X and y.")

    # train XGBoost model
    model, y_pred, y_test, X_test = k_fold_xgboost(X, y)
    log.info(f"Trained XGBoost model.")
    

    # plot confusion matrix for XGBoost
    fig, ax = plot_confusion_matrix(y_test, y_pred)
    fig.savefig("plots/confusion_matrix_xgboost_train.png")
    log.info(f"Confusion matrix saved to plots/confusion_matrix_xgboost_test.png")

    # plot actual vs predicted for XGBoost
    fig, ax = plot_actual_vs_predicted(y_test, y_pred)
    fig.savefig("plots/actual_vs_predicted_xgboost_train.png")
    log.info(f"Actual vs predicted saved to plots/actual_vs_predicted_xgboost_test.png")

    # plot feature importance for XGBoost
    importance = feature_check(model)
    fig, ax = plot_feature_importance(X_test, importance)
    fig.savefig("plots/feature_importance_xgboost.png")
    log.info(f"Feature importance saved to plots/feature_importance_xgboost.png")
    
    # plot permutation importance for XGBoost
    perm = permutation_check(model, X_test, y_test)
    fig, ax = plot_permutation_importance(X_test, perm)
    fig.savefig("plots/permutation_importance_xgboost.png")
    log.info(f"Permutation importance saved to plots/permutation_importance_xgboost.png")


    # train LightGBM model
    model, y_pred, y_test, X_test = k_fold_lightgbm(X, y)
    log.info(f"Trained LightGBM model.")
    # run model on test set
    y_pred_test = model.predict(X_test)
    # plot confusion matrix for LightGBM
    fig, ax = plot_confusion_matrix(y_test, y_pred)
    fig.savefig("plots/confusion_matrix_lightgbm_train.png")
    log.info(f"Confusion matrix saved to plots/confusion_matrix_lightgbm_test.png")

    # plot actual vs predicted for LightGBM
    fig, ax = plot_actual_vs_predicted(y_test, y_pred)
    fig.savefig("plots/actual_vs_predicted_lightgbm_train.png")
    log.info(f"Actual vs predicted saved to plots/actual_vs_predicted_lightgbm_test.png")

    # plot feature importance for LightGBM
    importance = feature_check(model)
    fig, ax = plot_feature_importance(X_test, importance)
    fig.savefig("plots/feature_importance_lightgbm.png")
    log.info(f"Feature importance saved to plots/feature_importance_lightgbm.png")

    # plot permutation importance for LightGBM
    perm = permutation_check(model, X_test, y_test)
    fig, ax = plot_permutation_importance(X_test, perm)
    fig.savefig("plots/permutation_importance_lightgbm.png")
    log.info(f"Permutation importance saved to plots/permutation_importance_lightgbm.png")

    
    return None



# -----------------------------------------
# 5. MAIN OPTION FUNCTIONS

def run_pca_spca(path, choice, df = None):
    
        # load dataset
        if choice == 1:
            df = load_single_csv(path)
        elif choice == 2:
            df = load_all_csv(path)
        # drop timestamp column
        df = df.drop("ts", axis=1)
        # split dataset into X and y
        X, y = split_dataset(df, target="grasp")
        log.info(f"Dataset loaded and split into X and y.")
    
        # run PCA
        X_pca = pca(X)
        log.info(f"PCA completed.")
    
        # run SPCA
        X_spca = spca(X)
        log.info(f"SPCA completed.")
    
        # plot PCA
        fig, ax = plot_pca(X_pca, y)
        fig.savefig("plots/pca.png")
        log.info(f"PCA plot saved to plots/pca.png")
    
        # plot SPCA
        fig, ax = plot_spca(X_spca, y)
        fig.savefig("plots/spca.png")
        log.info(f"SPCA plot saved to plots/spca.png")
    
        return None







# -----------------------------------------
# 5. MAIN MENU

def main_menu():

    # path to the dataset
    path = "data/processed_data/subject_010.csv"
    path_all = "data/processed_data/"

    console = Console()
    
    while True:
        console.clear()
        console.print("XBOOST-importance Program Selector", style="bold underline")
        console.print("1. Run xgboost-main on test subject")
        console.print("2. Run xgboost-main on all subjects")
        console.print("3. Run pca and spca on test subjects")
        #console.print("4. Run pca and spca on all subjects")
        console.print("5. Run all trial programs")
        #console.print("6. Run all programs on all subjects")
        console.print("0. Exit")

        choice = console.input("Enter your choice : ")
        
        if choice == "0":
            console.print("Exiting program.")
            break
        elif choice == "1":
            # Call your xgboost-main function with the appropriate arguments
            console.print("Running xgboost-main on the test subject...")
            xgboost_main(path, 1)
        elif choice == "2":
            console.print("Running xgboost-main on all subjects...")
            log.info("All files not available yet... have not performed extraction.")
            # Replace the following line with your actual function call
            # xgboost_main(path_all, 2)
        elif choice == "3":
            console.print("Running pca and spca on test subjects...")
            # Replace the following line with your actual function call
            run_pca_spca(path, 1)
        elif choice == "4":
            console.print("Running pca and spca on all subjects...")
            log.info("All files not available yet... have not performed extraction.")
            # Replace the following line with your actual function call
            # run_pca_spca_all(path_all, 2)
        elif choice == "5":
            console.print("Running all trial programs...")
            # Replace the following line with your actual function call
            xgboost_main(path, 3)
        elif choice == "6":
            console.print("Running all programs on all subjects...")
            # Replace the following line with your actual function call
            # run_all_programs(path_all)
        else:
            console.print("Invalid choice. Please enter a valid option (0-6).")




# run main function
if __name__ == "__main__":
    
    main_menu()

    log.info("Program finished.")
    # exit the program
    exit(0)